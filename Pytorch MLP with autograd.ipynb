{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as f\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hod</th>\n",
       "      <th>sourcelong</th>\n",
       "      <th>sourcelat</th>\n",
       "      <th>dstlong</th>\n",
       "      <th>dstlat</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90320</th>\n",
       "      <td>0.036806</td>\n",
       "      <td>-1.190965</td>\n",
       "      <td>0.163744</td>\n",
       "      <td>-0.988400</td>\n",
       "      <td>1.716541</td>\n",
       "      <td>0.648271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83028</th>\n",
       "      <td>0.457357</td>\n",
       "      <td>0.333569</td>\n",
       "      <td>-2.436622</td>\n",
       "      <td>0.180096</td>\n",
       "      <td>-1.756452</td>\n",
       "      <td>-0.520837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11867</th>\n",
       "      <td>0.877907</td>\n",
       "      <td>0.664416</td>\n",
       "      <td>-1.118368</td>\n",
       "      <td>-0.022824</td>\n",
       "      <td>-1.621043</td>\n",
       "      <td>-0.648328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62691</th>\n",
       "      <td>0.737724</td>\n",
       "      <td>1.756825</td>\n",
       "      <td>-1.033331</td>\n",
       "      <td>1.056976</td>\n",
       "      <td>-2.095188</td>\n",
       "      <td>-0.195192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105034</th>\n",
       "      <td>0.457357</td>\n",
       "      <td>0.478419</td>\n",
       "      <td>1.181438</td>\n",
       "      <td>0.285093</td>\n",
       "      <td>0.107508</td>\n",
       "      <td>-0.378492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             hod  sourcelong  sourcelat   dstlong    dstlat  distance\n",
       "90320   0.036806   -1.190965   0.163744 -0.988400  1.716541  0.648271\n",
       "83028   0.457357    0.333569  -2.436622  0.180096 -1.756452 -0.520837\n",
       "11867   0.877907    0.664416  -1.118368 -0.022824 -1.621043 -0.648328\n",
       "62691   0.737724    1.756825  -1.033331  1.056976 -2.095188 -0.195192\n",
       "105034  0.457357    0.478419   1.181438  0.285093  0.107508 -0.378492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Read and split dataset\n",
    "bucket = 'sagemaker-ann-fyp'\n",
    "data_key = 'complete_dataset.csv' \n",
    "travel_data = 's3://{}/{}'.format(bucket,data_key)\n",
    "\n",
    "full_dataset = pd.read_csv(travel_data)\n",
    "\n",
    "dataset_features = ['hod','sourcelong','sourcelat','dstlong','dstlat','distance']\n",
    "X = full_dataset[dataset_features]\n",
    "y = full_dataset['mean_travel_time']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y,random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_X_scaled = pd.DataFrame(scaler.fit_transform(train_X), columns = train_X.columns, index = train_X.index)\n",
    "test_X_scaled = pd.DataFrame(scaler.transform(test_X), columns = test_X.columns, index = test_X.index)\n",
    "\n",
    "display(train_X_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90320</th>\n",
       "      <td>-2.021198</td>\n",
       "      <td>-0.665633</td>\n",
       "      <td>0.151666</td>\n",
       "      <td>0.283261</td>\n",
       "      <td>-0.357851</td>\n",
       "      <td>1.015216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83028</th>\n",
       "      <td>2.799813</td>\n",
       "      <td>-1.163442</td>\n",
       "      <td>0.457039</td>\n",
       "      <td>-0.075395</td>\n",
       "      <td>-0.155893</td>\n",
       "      <td>0.463657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11867</th>\n",
       "      <td>2.015665</td>\n",
       "      <td>-0.605590</td>\n",
       "      <td>0.656430</td>\n",
       "      <td>-0.630789</td>\n",
       "      <td>0.459530</td>\n",
       "      <td>-0.204796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62691</th>\n",
       "      <td>2.902472</td>\n",
       "      <td>0.608853</td>\n",
       "      <td>0.809908</td>\n",
       "      <td>-0.048219</td>\n",
       "      <td>0.661587</td>\n",
       "      <td>-0.593746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105034</th>\n",
       "      <td>-0.425712</td>\n",
       "      <td>0.890031</td>\n",
       "      <td>0.185729</td>\n",
       "      <td>-0.711251</td>\n",
       "      <td>0.331717</td>\n",
       "      <td>-0.667946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5\n",
       "90320  -2.021198 -0.665633  0.151666  0.283261 -0.357851  1.015216\n",
       "83028   2.799813 -1.163442  0.457039 -0.075395 -0.155893  0.463657\n",
       "11867   2.015665 -0.605590  0.656430 -0.630789  0.459530 -0.204796\n",
       "62691   2.902472  0.608853  0.809908 -0.048219  0.661587 -0.593746\n",
       "105034 -0.425712  0.890031  0.185729 -0.711251  0.331717 -0.667946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79481</th>\n",
       "      <td>1.045308</td>\n",
       "      <td>-0.665287</td>\n",
       "      <td>-0.418263</td>\n",
       "      <td>1.051124</td>\n",
       "      <td>0.321068</td>\n",
       "      <td>1.082427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146145</th>\n",
       "      <td>-0.964215</td>\n",
       "      <td>-0.498421</td>\n",
       "      <td>1.814077</td>\n",
       "      <td>0.496389</td>\n",
       "      <td>-0.396297</td>\n",
       "      <td>1.056667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40592</th>\n",
       "      <td>1.227338</td>\n",
       "      <td>-0.334246</td>\n",
       "      <td>-0.933212</td>\n",
       "      <td>0.260315</td>\n",
       "      <td>0.387803</td>\n",
       "      <td>-0.828079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73084</th>\n",
       "      <td>-0.705346</td>\n",
       "      <td>-1.794293</td>\n",
       "      <td>-0.927249</td>\n",
       "      <td>1.310492</td>\n",
       "      <td>-0.668066</td>\n",
       "      <td>-0.623207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35092</th>\n",
       "      <td>0.735108</td>\n",
       "      <td>0.949831</td>\n",
       "      <td>-0.743403</td>\n",
       "      <td>-0.391301</td>\n",
       "      <td>0.393696</td>\n",
       "      <td>-0.172679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5\n",
       "79481   1.045308 -0.665287 -0.418263  1.051124  0.321068  1.082427\n",
       "146145 -0.964215 -0.498421  1.814077  0.496389 -0.396297  1.056667\n",
       "40592   1.227338 -0.334246 -0.933212  0.260315  0.387803 -0.828079\n",
       "73084  -0.705346 -1.794293 -0.927249  1.310492 -0.668066 -0.623207\n",
       "35092   0.735108  0.949831 -0.743403 -0.391301  0.393696 -0.172679"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components = None)\n",
    "\n",
    "train_X_reduced = pd.DataFrame(pca.fit_transform(train_X_scaled), index = train_X_scaled.index)\n",
    "test_X_reduced = pd.DataFrame(pca.transform(test_X_scaled), index = test_X_scaled.index)\n",
    "\n",
    "display(train_X_reduced.head())\n",
    "display(test_X_reduced.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0212, -0.6656,  0.1517,  0.2833, -0.3579,  1.0152],\n",
      "        [ 2.7998, -1.1634,  0.4570, -0.0754, -0.1559,  0.4637],\n",
      "        [ 2.0157, -0.6056,  0.6564, -0.6308,  0.4595, -0.2048],\n",
      "        ...,\n",
      "        [-0.6850, -0.9409,  0.0571, -0.2627, -0.5556, -0.0088],\n",
      "        [ 1.5405, -2.1940, -0.9850, -0.4123,  0.1528, -0.1472],\n",
      "        [ 2.3565, -1.5193, -1.6366,  0.4402, -0.2102,  0.3595]])\n"
     ]
    }
   ],
   "source": [
    "train_X_reduced = torch.FloatTensor(train_X_reduced.values)\n",
    "test_X_reduced = torch.FloatTensor(test_X_reduced.values)\n",
    "\n",
    "train_y = torch.FloatTensor(train_y.values)\n",
    "test_y = torch.FloatTensor(test_y.values)\n",
    "\n",
    "print(train_X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_X_reduced,train_y)\n",
    "test_data = TensorDataset(test_X_reduced,test_y)\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim=1):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        assert out_dim==1, 'out_dim must be 1'\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "         #creating a module list of hidden layers & adding the input layer as 1st layer in the list\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(self.in_dim, self.hidden_dim[0])])\n",
    "        \n",
    "        #create a list of hidden layers by pairing hidden layer dims, and a for loop to create layers \n",
    "        #depending on given list of dimensions\n",
    "        hidden_layer_sizes = zip(self.hidden_dim[:-1], self.hidden_dim[1:])\n",
    "        for (layer_in, layer_out) in hidden_layer_sizes:\n",
    "            self.hidden_layers.extend([nn.Linear(layer_in, layer_out)])\n",
    "        #creates the last layer    \n",
    "        self.output = nn.Linear(self.hidden_dim[-1], self.out_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #a for loop to loop through each layer in the hidden layer module list\n",
    "        for h_layer in iter(self.hidden_layers):\n",
    "            x = self.dropout(torch.relu(h_layer(x)))\n",
    "\n",
    "        x = self.output(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_loss(y_pred, y_true):\n",
    "    mae = torch.abs(y_true - y_pred).mean()\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=6, out_features=14, bias=True)\n",
      "    (1): Linear(in_features=14, out_features=10, bias=True)\n",
      "    (2): Linear(in_features=10, out_features=6, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=6, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(train_X.shape[1], [14,10,6], 1).to(device)\n",
    "print(mlp)\n",
    "optimizer = optim.Adam(mlp.parameters(),lr=0.001)\n",
    "criterion = nn.L1Loss()\n",
    "#scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr = 0.0001, max_lr = 0.003, step_size_up = 20, cycle_momentum = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "mlp = MLP(train_X.shape[1], [16,12,10,8,6,4], 1).to(device)\n",
    "print(mlp)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adagrad(mlp.parameters(),lr=0.0001, lr_decay = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Batch:562/562 Loss:1034.6433 Time:0m4.14s\n",
      "Valid Loss:961.5638\n",
      "Epoch:2 Batch:562/562 Loss:1048.5906 Time:0m2.59s\n",
      "Valid Loss:664.7542\n",
      "Epoch:3 Batch:562/562 Loss:959.3257 Time:0m3.59ss\n",
      "Valid Loss:637.2838\n",
      "Epoch:4 Batch:562/562 Loss:1037.1322 Time:0m3.36s\n",
      "Valid Loss:599.1195\n",
      "Epoch:5 Batch:562/562 Loss:998.6840 Time:0m3.09ss\n",
      "Valid Loss:600.0017\n",
      "Epoch:6 Batch:562/562 Loss:849.1636 Time:0m3.57ss\n",
      "Valid Loss:594.6844\n",
      "Epoch:7 Batch:562/562 Loss:903.6855 Time:0m3.54ss\n",
      "Valid Loss:588.4672\n",
      "Epoch:8 Batch:562/562 Loss:924.4380 Time:0m3.49ss\n",
      "Valid Loss:605.4903\n",
      "Epoch:9 Batch:562/562 Loss:874.1814 Time:0m2.83ss\n",
      "Valid Loss:578.4463\n",
      "Epoch:10 Batch:562/562 Loss:1011.4975 Time:0m3.28s\n",
      "Valid Loss:599.6528\n",
      "Epoch:11 Batch:562/562 Loss:864.8408 Time:0m2.22ss\n",
      "Valid Loss:590.9661\n",
      "Epoch:12 Batch:562/562 Loss:829.2884 Time:0m2.87ss\n",
      "Valid Loss:541.0718\n",
      "Epoch:13 Batch:562/562 Loss:850.9263 Time:0m3.06s\n",
      "Valid Loss:544.1455\n",
      "Epoch:14 Batch:562/562 Loss:886.0880 Time:0m3.28ss\n",
      "Valid Loss:541.0594\n",
      "Epoch:15 Batch:562/562 Loss:841.1636 Time:0m2.97ss\n",
      "Valid Loss:535.4987\n",
      "Epoch:16 Batch:562/562 Loss:830.9048 Time:0m1.95ss\n",
      "Valid Loss:542.4014\n",
      "Epoch:17 Batch:562/562 Loss:861.4536 Time:0m3.20s\n",
      "Valid Loss:537.9439\n",
      "Epoch:18 Batch:562/562 Loss:912.6678 Time:0m3.48s\n",
      "Valid Loss:539.4746\n",
      "Epoch:19 Batch:562/562 Loss:804.9944 Time:0m2.80ss\n",
      "Valid Loss:538.5300\n",
      "Epoch:20 Batch:562/562 Loss:748.6002 Time:0m3.59ss\n",
      "Valid Loss:539.0992\n",
      "Epoch:21 Batch:562/562 Loss:747.7625 Time:0m3.10ss\n",
      "Valid Loss:539.9847\n",
      "Epoch:22 Batch:562/562 Loss:781.6911 Time:0m2.73ss\n",
      "Valid Loss:549.6439\n",
      "Epoch:23 Batch:562/562 Loss:794.2770 Time:0m2.32s\n",
      "Valid Loss:538.5221\n",
      "Epoch:24 Batch:562/562 Loss:881.2271 Time:0m2.45ss\n",
      "Valid Loss:535.1012\n",
      "Epoch:25 Batch:562/562 Loss:850.1685 Time:0m2.76ss\n",
      "Valid Loss:540.5109\n",
      "Epoch:26 Batch:562/562 Loss:903.3458 Time:0m3.46s\n",
      "Valid Loss:537.3345\n",
      "Epoch:27 Batch:562/562 Loss:852.5822 Time:0m2.27ss\n",
      "Valid Loss:543.8204\n",
      "Epoch:28 Batch:562/562 Loss:842.5608 Time:0m3.58ss\n",
      "Valid Loss:546.1943\n",
      "Epoch:29 Batch:562/562 Loss:849.1022 Time:0m3.15s\n",
      "Valid Loss:525.9408\n",
      "Epoch:30 Batch:562/562 Loss:810.6606 Time:0m3.43s\n",
      "Valid Loss:543.5825\n",
      "Epoch:31 Batch:562/562 Loss:876.6200 Time:0m3.72s\n",
      "Valid Loss:552.4564\n",
      "Epoch:32 Batch:562/562 Loss:904.9864 Time:0m3.53ss\n",
      "Valid Loss:544.1955\n",
      "Epoch:33 Batch:562/562 Loss:766.6803 Time:0m2.66s\n",
      "Valid Loss:541.6781\n",
      "Epoch:34 Batch:562/562 Loss:802.3126 Time:0m2.37ss\n",
      "Valid Loss:537.5250\n",
      "Epoch:35 Batch:562/562 Loss:774.4274 Time:0m3.53ss\n",
      "Valid Loss:541.0782\n",
      "Epoch:36 Batch:562/562 Loss:876.4980 Time:0m3.47ss\n",
      "Valid Loss:535.5858\n",
      "Epoch:37 Batch:562/562 Loss:926.3444 Time:0m3.32s\n",
      "Valid Loss:539.0698\n",
      "Epoch:38 Batch:562/562 Loss:882.8336 Time:0m3.50ss\n",
      "Valid Loss:544.0841\n",
      "Epoch:39 Batch:562/562 Loss:943.1906 Time:0m3.57s\n",
      "Valid Loss:527.4221\n",
      "Epoch:40 Batch:562/562 Loss:760.0308 Time:0m2.99s\n",
      "Valid Loss:538.5520\n",
      "Epoch:41 Batch:562/562 Loss:895.9509 Time:0m3.57ss\n",
      "Valid Loss:536.1415\n",
      "Epoch:42 Batch:562/562 Loss:824.4883 Time:0m3.37s\n",
      "Valid Loss:541.1423\n",
      "Epoch:43 Batch:562/562 Loss:821.0582 Time:0m3.11s\n",
      "Valid Loss:538.6622\n",
      "Epoch:44 Batch:562/562 Loss:866.2506 Time:0m2.63s\n",
      "Valid Loss:539.8730\n",
      "Epoch:45 Batch:562/562 Loss:749.8221 Time:0m3.21s\n",
      "Valid Loss:530.6019\n",
      "Epoch:46 Batch:562/562 Loss:807.2786 Time:0m2.79s\n",
      "Valid Loss:539.1623\n",
      "Epoch:47 Batch:562/562 Loss:772.0250 Time:0m3.22s\n",
      "Valid Loss:536.1802\n",
      "Epoch:48 Batch:562/562 Loss:828.8414 Time:0m2.32ss\n",
      "Valid Loss:537.3572\n",
      "Epoch:49 Batch:562/562 Loss:773.7280 Time:0m3.15s\n",
      "Valid Loss:536.9587\n",
      "Epoch:50 Batch:562/562 Loss:713.1835 Time:0m2.54s\n",
      "Valid Loss:526.2206\n",
      "Epoch:51 Batch:562/562 Loss:777.5202 Time:0m2.49s\n",
      "Valid Loss:537.5162\n",
      "Epoch:52 Batch:562/562 Loss:849.7017 Time:0m2.93s\n",
      "Valid Loss:537.9793\n",
      "Epoch:53 Batch:562/562 Loss:769.6378 Time:0m3.64s\n",
      "Valid Loss:531.4822\n",
      "Epoch:54 Batch:562/562 Loss:750.1209 Time:0m3.44s\n",
      "Valid Loss:530.9880\n",
      "Epoch:55 Batch:562/562 Loss:807.6201 Time:0m3.44s\n",
      "Valid Loss:535.2259\n",
      "Epoch:56 Batch:562/562 Loss:779.7407 Time:0m2.55s\n",
      "Valid Loss:528.9827\n",
      "Epoch:57 Batch:562/562 Loss:822.0163 Time:0m2.64s\n",
      "Valid Loss:540.3968\n",
      "Epoch:58 Batch:562/562 Loss:844.4265 Time:0m3.51s\n",
      "Valid Loss:518.8531\n",
      "Epoch:59 Batch:562/562 Loss:776.2077 Time:0m3.46s\n",
      "Valid Loss:533.3737\n",
      "Epoch:60 Batch:562/562 Loss:892.4219 Time:0m3.55s\n",
      "Valid Loss:534.9903\n",
      "Epoch:61 Batch:562/562 Loss:844.1725 Time:0m3.63s\n",
      "Valid Loss:537.0078\n",
      "Epoch:62 Batch:562/562 Loss:809.6163 Time:0m1.90s\n",
      "Valid Loss:528.8431\n",
      "Epoch:63 Batch:562/562 Loss:736.6208 Time:0m1.94s\n",
      "Valid Loss:531.3361\n",
      "Epoch:64 Batch:562/562 Loss:745.0297 Time:0m1.95s\n",
      "Valid Loss:539.4028\n",
      "Epoch:65 Batch:562/562 Loss:829.8216 Time:0m2.63s\n",
      "Valid Loss:528.7764\n",
      "Epoch:66 Batch:562/562 Loss:872.2611 Time:0m2.57s\n",
      "Valid Loss:532.3253\n",
      "Epoch:67 Batch:562/562 Loss:838.8388 Time:0m3.49s\n",
      "Valid Loss:528.1885\n",
      "Epoch:68 Batch:562/562 Loss:752.5280 Time:0m2.37s\n",
      "Valid Loss:535.1805\n",
      "Epoch:69 Batch:562/562 Loss:759.5689 Time:0m3.65s\n",
      "Valid Loss:529.5703\n",
      "Epoch:70 Batch:562/562 Loss:743.2880 Time:0m3.38s\n",
      "Valid Loss:525.2047\n",
      "Epoch:71 Batch:562/562 Loss:819.7105 Time:0m2.54s\n",
      "Valid Loss:525.5123\n",
      "Epoch:72 Batch:562/562 Loss:846.6603 Time:0m2.29s\n",
      "Valid Loss:541.3326\n",
      "Epoch:73 Batch:562/562 Loss:762.0218 Time:0m2.84s\n",
      "Valid Loss:525.2915\n",
      "Epoch:74 Batch:562/562 Loss:813.0712 Time:0m2.27s\n",
      "Valid Loss:526.4553\n",
      "Epoch:75 Batch:562/562 Loss:695.0596 Time:0m2.49s\n",
      "Valid Loss:524.9532\n",
      "Epoch:76 Batch:562/562 Loss:772.8335 Time:0m2.56s\n",
      "Valid Loss:537.0819\n",
      "Epoch:77 Batch:562/562 Loss:841.7115 Time:0m3.44s\n",
      "Valid Loss:529.7105\n",
      "Epoch:78 Batch:562/562 Loss:719.3308 Time:0m3.10s\n",
      "Valid Loss:532.2414\n",
      "Epoch:79 Batch:562/562 Loss:876.6478 Time:0m2.73s\n",
      "Valid Loss:541.4551\n",
      "Epoch:80 Batch:562/562 Loss:646.6763 Time:0m4.13s\n",
      "Valid Loss:533.3134\n",
      "Epoch:81 Batch:562/562 Loss:768.3539 Time:0m3.84s\n",
      "Valid Loss:532.6725\n",
      "Epoch:82 Batch:562/562 Loss:821.9460 Time:0m2.84s\n",
      "Valid Loss:533.4523\n",
      "Epoch:83 Batch:562/562 Loss:808.4897 Time:0m2.37s\n",
      "Valid Loss:523.5499\n",
      "Epoch:84 Batch:562/562 Loss:774.2009 Time:0m1.85s\n",
      "Valid Loss:518.4857\n",
      "Epoch:85 Batch:562/562 Loss:758.7252 Time:0m2.02ss\n",
      "Valid Loss:523.0622\n",
      "Epoch:86 Batch:562/562 Loss:754.2390 Time:0m3.21s\n",
      "Valid Loss:528.2343\n",
      "Epoch:87 Batch:562/562 Loss:772.0532 Time:0m2.80s\n",
      "Valid Loss:527.1612\n",
      "Epoch:88 Batch:562/562 Loss:700.1749 Time:0m2.84s\n",
      "Valid Loss:529.8173\n",
      "Epoch:89 Batch:562/562 Loss:800.9717 Time:0m3.43s\n",
      "Valid Loss:537.2782\n",
      "Epoch:90 Batch:562/562 Loss:776.1343 Time:0m2.66s\n",
      "Valid Loss:526.8960\n",
      "Epoch:91 Batch:562/562 Loss:841.9942 Time:0m3.06s\n",
      "Valid Loss:527.4221\n",
      "Epoch:92 Batch:562/562 Loss:721.0288 Time:0m2.45s\n",
      "Valid Loss:532.2038\n",
      "Epoch:93 Batch:562/562 Loss:705.2758 Time:0m2.55s\n",
      "Valid Loss:535.0629\n",
      "Epoch:94 Batch:562/562 Loss:798.4650 Time:0m2.67s\n",
      "Valid Loss:530.6199\n",
      "Epoch:95 Batch:562/562 Loss:783.5963 Time:0m1.94s\n",
      "Valid Loss:518.6336\n",
      "Epoch:96 Batch:562/562 Loss:748.6211 Time:0m2.16s\n",
      "Valid Loss:517.6713\n",
      "Epoch:97 Batch:562/562 Loss:694.7323 Time:0m3.71s\n",
      "Valid Loss:531.3606\n",
      "Epoch:98 Batch:562/562 Loss:794.0443 Time:0m2.54s\n",
      "Valid Loss:528.0074\n",
      "Epoch:99 Batch:562/562 Loss:781.1638 Time:0m2.36s\n",
      "Valid Loss:526.8657\n",
      "Epoch:100 Batch:562/562 Loss:766.2814 Time:0m2.79s\n",
      "Valid Loss:526.0355\n",
      "Epoch:101 Batch:562/562 Loss:814.6389 Time:0m2.88s\n",
      "Valid Loss:528.8782\n",
      "Epoch:102 Batch:562/562 Loss:692.3275 Time:0m1.92s\n",
      "Valid Loss:519.5482\n",
      "Epoch:103 Batch:562/562 Loss:788.2544 Time:0m1.93s\n",
      "Valid Loss:523.9516\n",
      "Epoch:104 Batch:562/562 Loss:872.4772 Time:0m2.78s\n",
      "Valid Loss:528.3851\n",
      "Epoch:105 Batch:562/562 Loss:747.1185 Time:0m2.87s\n",
      "Valid Loss:535.2951\n",
      "Epoch:106 Batch:562/562 Loss:842.9784 Time:0m2.91s\n",
      "Valid Loss:521.3071\n",
      "Epoch:107 Batch:562/562 Loss:770.0939 Time:0m2.75s\n",
      "Valid Loss:531.6278\n",
      "Epoch:108 Batch:562/562 Loss:694.4211 Time:0m2.45s\n",
      "Valid Loss:531.4695\n",
      "Epoch:109 Batch:562/562 Loss:753.3275 Time:0m3.72s\n",
      "Valid Loss:525.5782\n",
      "Epoch:110 Batch:562/562 Loss:849.4120 Time:0m3.21s\n",
      "Valid Loss:525.2139\n",
      "Epoch:111 Batch:562/562 Loss:777.5356 Time:0m2.07s\n",
      "Valid Loss:527.8603\n",
      "Epoch:112 Batch:562/562 Loss:827.5442 Time:0m2.80s\n",
      "Valid Loss:533.5391\n",
      "Epoch:113 Batch:562/562 Loss:757.0417 Time:0m2.03s\n",
      "Valid Loss:538.4253\n",
      "Epoch:114 Batch:562/562 Loss:821.7744 Time:0m3.18s\n",
      "Valid Loss:524.7652\n",
      "Epoch:115 Batch:562/562 Loss:810.1907 Time:0m2.49s\n",
      "Valid Loss:528.6535\n",
      "Epoch:116 Batch:562/562 Loss:764.8289 Time:0m3.11s\n",
      "Valid Loss:523.0564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:117 Batch:562/562 Loss:704.1441 Time:0m3.06s\n",
      "Valid Loss:517.5082\n",
      "Epoch:118 Batch:562/562 Loss:770.1239 Time:0m3.00s\n",
      "Valid Loss:521.3782\n",
      "Epoch:119 Batch:562/562 Loss:784.3489 Time:0m1.88s\n",
      "Valid Loss:527.5085\n",
      "Epoch:120 Batch:562/562 Loss:749.2241 Time:0m2.84s\n",
      "Valid Loss:523.9756\n",
      "Epoch:121 Batch:562/562 Loss:794.5632 Time:0m3.02s\n",
      "Valid Loss:522.9572\n",
      "Epoch:122 Batch:562/562 Loss:752.9088 Time:0m1.84s\n",
      "Valid Loss:526.7270\n",
      "Epoch:123 Batch:562/562 Loss:830.8003 Time:0m2.42s\n",
      "Valid Loss:526.3635\n",
      "Epoch:124 Batch:562/562 Loss:801.7767 Time:0m2.81s\n",
      "Valid Loss:520.0997\n",
      "Epoch:125 Batch:562/562 Loss:812.1210 Time:0m3.49s\n",
      "Valid Loss:523.3638\n",
      "Epoch:126 Batch:562/562 Loss:755.5359 Time:0m2.18s\n",
      "Valid Loss:523.2233\n",
      "Epoch:127 Batch:562/562 Loss:804.6017 Time:0m1.95s\n",
      "Valid Loss:520.8895\n",
      "Epoch:128 Batch:562/562 Loss:756.9119 Time:0m3.48s\n",
      "Valid Loss:519.9829\n",
      "Epoch:129 Batch:562/562 Loss:698.5218 Time:0m3.46s\n",
      "Valid Loss:522.4010\n",
      "Epoch:130 Batch:562/562 Loss:715.8314 Time:0m2.67s\n",
      "Valid Loss:518.6977\n",
      "Epoch:131 Batch:562/562 Loss:708.6420 Time:0m3.16s\n",
      "Valid Loss:522.6058\n",
      "Epoch:132 Batch:562/562 Loss:674.4842 Time:0m3.37s\n",
      "Valid Loss:514.9829\n",
      "Epoch:133 Batch:562/562 Loss:804.4290 Time:0m3.48s\n",
      "Valid Loss:527.9889\n",
      "Epoch:134 Batch:562/562 Loss:718.6949 Time:0m3.25s\n",
      "Valid Loss:522.2008\n",
      "Epoch:135 Batch:562/562 Loss:778.4106 Time:0m2.88s\n",
      "Valid Loss:527.8774\n",
      "Epoch:136 Batch:562/562 Loss:781.7563 Time:0m3.19s\n",
      "Valid Loss:526.3085\n",
      "Epoch:137 Batch:562/562 Loss:699.8973 Time:0m2.32s\n",
      "Valid Loss:528.6750\n",
      "Epoch:138 Batch:562/562 Loss:736.2786 Time:0m3.01s\n",
      "Valid Loss:518.5614\n",
      "Epoch:139 Batch:562/562 Loss:680.5652 Time:0m3.47s\n",
      "Valid Loss:529.1420\n",
      "Epoch:140 Batch:562/562 Loss:702.9851 Time:0m3.36s\n",
      "Valid Loss:521.9925\n",
      "Epoch:141 Batch:562/562 Loss:771.2471 Time:0m2.53s\n",
      "Valid Loss:526.9940\n",
      "Epoch:142 Batch:562/562 Loss:873.5101 Time:0m2.26s\n",
      "Valid Loss:515.1761\n",
      "Epoch:143 Batch:562/562 Loss:793.8250 Time:0m2.75s\n",
      "Valid Loss:526.0436\n",
      "Epoch:144 Batch:562/562 Loss:827.5780 Time:0m2.41s\n",
      "Valid Loss:522.1709\n",
      "Epoch:145 Batch:562/562 Loss:650.8326 Time:0m3.13s\n",
      "Valid Loss:538.1606\n",
      "Epoch:146 Batch:562/562 Loss:725.3163 Time:0m2.92s\n",
      "Valid Loss:520.3648\n",
      "Epoch:147 Batch:562/562 Loss:768.5529 Time:0m3.59s\n",
      "Valid Loss:526.8005\n",
      "Epoch:148 Batch:562/562 Loss:782.3099 Time:0m1.98s\n",
      "Valid Loss:531.1640\n",
      "Epoch:149 Batch:562/562 Loss:875.0552 Time:0m2.59s\n",
      "Valid Loss:517.1787\n",
      "Epoch:150 Batch:562/562 Loss:814.1377 Time:0m2.16s\n",
      "Valid Loss:529.1653\n",
      "Epoch:151 Batch:562/562 Loss:803.7729 Time:0m2.22s\n",
      "Valid Loss:521.4788\n",
      "Epoch:152 Batch:562/562 Loss:721.7141 Time:0m3.54s\n",
      "Valid Loss:524.3374\n",
      "Epoch:153 Batch:562/562 Loss:665.9658 Time:0m3.48s\n",
      "Valid Loss:516.3849\n",
      "Epoch:154 Batch:562/562 Loss:775.0870 Time:0m3.32s\n",
      "Valid Loss:519.8312\n",
      "Epoch:155 Batch:562/562 Loss:762.2622 Time:0m2.64s\n",
      "Valid Loss:520.0786\n",
      "Epoch:156 Batch:562/562 Loss:772.0479 Time:0m2.81s\n",
      "Valid Loss:522.3693\n",
      "Epoch:157 Batch:562/562 Loss:733.4252 Time:0m2.63s\n",
      "Valid Loss:520.4316\n",
      "Epoch:158 Batch:562/562 Loss:761.5124 Time:0m2.81s\n",
      "Valid Loss:529.0989\n",
      "Epoch:159 Batch:562/562 Loss:761.5522 Time:0m3.09s\n",
      "Valid Loss:518.2307\n",
      "Epoch:160 Batch:562/562 Loss:805.0861 Time:0m3.34s\n",
      "Valid Loss:524.6252\n",
      "Epoch:161 Batch:562/562 Loss:768.5605 Time:0m3.50s\n",
      "Valid Loss:520.2870\n",
      "Epoch:162 Batch:562/562 Loss:883.3645 Time:0m3.60s\n",
      "Valid Loss:525.3779\n",
      "Epoch:163 Batch:562/562 Loss:710.6759 Time:0m3.46s\n",
      "Valid Loss:516.6950\n",
      "Epoch:164 Batch:562/562 Loss:897.6509 Time:0m3.73s\n",
      "Valid Loss:529.6909\n",
      "Epoch:165 Batch:562/562 Loss:888.5919 Time:0m1.90s\n",
      "Valid Loss:517.8895\n",
      "Epoch:166 Batch:562/562 Loss:720.9246 Time:0m1.98s\n",
      "Valid Loss:527.6734\n",
      "Epoch:167 Batch:562/562 Loss:793.2824 Time:0m3.18s\n",
      "Valid Loss:513.3262\n",
      "Epoch:168 Batch:562/562 Loss:787.2504 Time:0m3.33s\n",
      "Valid Loss:523.0714\n",
      "Epoch:169 Batch:562/562 Loss:706.9429 Time:0m3.52s\n",
      "Valid Loss:529.6503\n",
      "Epoch:170 Batch:562/562 Loss:792.9898 Time:0m2.68s\n",
      "Valid Loss:525.4517\n",
      "Epoch:171 Batch:562/562 Loss:776.2424 Time:0m3.54s\n",
      "Valid Loss:523.7232\n",
      "Epoch:172 Batch:562/562 Loss:687.4814 Time:0m4.12s\n",
      "Valid Loss:526.3016\n",
      "Epoch:173 Batch:562/562 Loss:685.9990 Time:0m3.42s\n",
      "Valid Loss:530.5950\n",
      "Epoch:174 Batch:562/562 Loss:844.7429 Time:0m3.28s\n",
      "Valid Loss:529.5395\n",
      "Epoch:175 Batch:562/562 Loss:754.8384 Time:0m3.10s\n",
      "Valid Loss:517.5564\n",
      "Epoch:176 Batch:562/562 Loss:863.5831 Time:0m3.07s\n",
      "Valid Loss:526.4897\n",
      "Epoch:177 Batch:562/562 Loss:800.7631 Time:0m3.56s\n",
      "Valid Loss:521.7045\n",
      "Epoch:178 Batch:562/562 Loss:920.5729 Time:0m3.85s\n",
      "Valid Loss:520.4254\n",
      "Epoch:179 Batch:562/562 Loss:788.1843 Time:0m3.46s\n",
      "Valid Loss:526.3588\n",
      "Epoch:180 Batch:562/562 Loss:743.1221 Time:0m2.95s\n",
      "Valid Loss:518.5054\n",
      "Epoch:181 Batch:562/562 Loss:797.5206 Time:0m3.57s\n",
      "Valid Loss:523.7482\n",
      "Epoch:182 Batch:562/562 Loss:762.0543 Time:0m4.19s\n",
      "Valid Loss:519.5308\n",
      "Epoch:183 Batch:562/562 Loss:757.1055 Time:0m2.78s\n",
      "Valid Loss:522.7777\n",
      "Epoch:184 Batch:562/562 Loss:700.1643 Time:0m2.30s\n",
      "Valid Loss:525.3476\n",
      "Epoch:185 Batch:562/562 Loss:830.3768 Time:0m3.01s\n",
      "Valid Loss:535.3704\n",
      "Epoch:186 Batch:562/562 Loss:723.9528 Time:0m2.57s\n",
      "Valid Loss:523.4035\n",
      "Epoch:187 Batch:562/562 Loss:683.6309 Time:0m2.38s\n",
      "Valid Loss:519.7561\n",
      "Epoch:188 Batch:562/562 Loss:724.4827 Time:0m2.99s\n",
      "Valid Loss:524.8004\n",
      "Epoch:189 Batch:562/562 Loss:728.2064 Time:0m3.14s\n",
      "Valid Loss:514.3148\n",
      "Epoch:190 Batch:562/562 Loss:736.0466 Time:0m2.48s\n",
      "Valid Loss:518.9549\n",
      "Epoch:191 Batch:562/562 Loss:828.6348 Time:0m1.99s\n",
      "Valid Loss:517.4547\n",
      "Epoch:192 Batch:562/562 Loss:842.4091 Time:0m2.17s\n",
      "Valid Loss:523.8992\n",
      "Epoch:193 Batch:562/562 Loss:744.7751 Time:0m2.04s\n",
      "Valid Loss:521.3290\n",
      "Epoch:194 Batch:562/562 Loss:759.5350 Time:0m1.96s\n",
      "Valid Loss:520.5704\n",
      "Epoch:195 Batch:562/562 Loss:677.1902 Time:0m2.44s\n",
      "Valid Loss:526.0323\n",
      "Epoch:196 Batch:562/562 Loss:741.5062 Time:0m1.91s\n",
      "Valid Loss:522.5005\n",
      "Epoch:197 Batch:562/562 Loss:790.7724 Time:0m3.32s\n",
      "Valid Loss:520.5273\n",
      "Epoch:198 Batch:562/562 Loss:723.8718 Time:0m3.47s\n",
      "Valid Loss:522.5981\n",
      "Epoch:199 Batch:562/562 Loss:729.9064 Time:0m3.13s\n",
      "Valid Loss:525.3448\n",
      "Epoch:200 Batch:562/562 Loss:744.0927 Time:0m2.17s\n",
      "Valid Loss:521.5400\n",
      "Epoch:201 Batch:562/562 Loss:717.0546 Time:0m2.40s\n",
      "Valid Loss:528.9020\n",
      "Epoch:202 Batch:562/562 Loss:716.1014 Time:0m3.32s\n",
      "Valid Loss:524.0651\n",
      "Epoch:203 Batch:562/562 Loss:711.6658 Time:0m3.20s\n",
      "Valid Loss:522.7183\n",
      "Epoch:204 Batch:562/562 Loss:701.6689 Time:0m3.05s\n",
      "Valid Loss:516.2097\n",
      "Epoch:205 Batch:562/562 Loss:806.4362 Time:0m2.75s\n",
      "Valid Loss:519.7413\n",
      "Epoch:206 Batch:562/562 Loss:753.7560 Time:0m3.22s\n",
      "Valid Loss:522.3519\n",
      "Epoch:207 Batch:562/562 Loss:785.5784 Time:0m3.93s\n",
      "Valid Loss:519.4075\n",
      "Epoch:208 Batch:562/562 Loss:760.9743 Time:0m2.86s\n",
      "Valid Loss:517.9540\n",
      "Epoch:209 Batch:562/562 Loss:761.5137 Time:0m3.11s\n",
      "Valid Loss:522.6549\n",
      "Epoch:210 Batch:562/562 Loss:764.2395 Time:0m3.33s\n",
      "Valid Loss:520.2180\n",
      "Epoch:211 Batch:562/562 Loss:742.2964 Time:0m3.64s\n",
      "Valid Loss:527.2302\n",
      "Epoch:212 Batch:562/562 Loss:746.2435 Time:0m3.67s\n",
      "Valid Loss:519.9454\n",
      "Epoch:213 Batch:562/562 Loss:818.6241 Time:0m3.78s\n",
      "Valid Loss:524.4827\n",
      "Epoch:214 Batch:562/562 Loss:752.9924 Time:0m3.13s\n",
      "Valid Loss:521.8318\n",
      "Epoch:215 Batch:562/562 Loss:756.0378 Time:0m3.60s\n",
      "Valid Loss:525.6423\n",
      "Epoch:216 Batch:562/562 Loss:635.3405 Time:0m3.10s\n",
      "Valid Loss:521.8188\n",
      "Epoch:217 Batch:562/562 Loss:773.4365 Time:0m3.67s\n",
      "Valid Loss:519.3100\n",
      "Epoch:218 Batch:562/562 Loss:767.3179 Time:0m3.79s\n",
      "Valid Loss:525.3011\n",
      "Epoch:219 Batch:562/562 Loss:731.3594 Time:0m2.97s\n",
      "Valid Loss:516.4848\n",
      "Epoch:220 Batch:562/562 Loss:628.9778 Time:0m2.73s\n",
      "Valid Loss:520.6166\n",
      "Epoch:221 Batch:562/562 Loss:755.6734 Time:0m3.17s\n",
      "Valid Loss:515.6535\n",
      "Epoch:222 Batch:562/562 Loss:764.8011 Time:0m2.71s\n",
      "Valid Loss:524.4788\n",
      "Epoch:223 Batch:562/562 Loss:727.6597 Time:0m2.32s\n",
      "Valid Loss:525.7741\n",
      "Epoch:224 Batch:562/562 Loss:674.2748 Time:0m3.25s\n",
      "Valid Loss:523.1669\n",
      "Epoch:225 Batch:562/562 Loss:752.5372 Time:0m2.36s\n",
      "Valid Loss:522.6574\n",
      "Epoch:226 Batch:562/562 Loss:790.6305 Time:0m3.51s\n",
      "Valid Loss:517.3527\n",
      "Epoch:227 Batch:562/562 Loss:763.9919 Time:0m2.96s\n",
      "Valid Loss:523.1111\n",
      "Epoch:228 Batch:562/562 Loss:726.5215 Time:0m2.08s\n",
      "Valid Loss:516.3059\n",
      "Epoch:229 Batch:562/562 Loss:803.6624 Time:0m2.33s\n",
      "Valid Loss:520.3006\n",
      "Epoch:230 Batch:562/562 Loss:773.0938 Time:0m2.42s\n",
      "Valid Loss:517.2465\n",
      "Epoch:231 Batch:562/562 Loss:776.8684 Time:0m2.95s\n",
      "Valid Loss:509.9608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:232 Batch:562/562 Loss:738.4147 Time:0m2.11s\n",
      "Valid Loss:520.0150\n",
      "Epoch:233 Batch:562/562 Loss:856.9719 Time:0m3.13s\n",
      "Valid Loss:521.4664\n",
      "Epoch:234 Batch:562/562 Loss:747.9147 Time:0m2.36s\n",
      "Valid Loss:524.3011\n",
      "Epoch:235 Batch:562/562 Loss:758.6172 Time:0m3.79s\n",
      "Valid Loss:522.0909\n",
      "Epoch:236 Batch:562/562 Loss:742.0250 Time:0m3.62s\n",
      "Valid Loss:517.3048\n",
      "Epoch:237 Batch:562/562 Loss:675.8254 Time:0m2.70s\n",
      "Valid Loss:518.2181\n",
      "Epoch:238 Batch:562/562 Loss:753.5883 Time:0m2.00s\n",
      "Valid Loss:524.0203\n",
      "Epoch:239 Batch:562/562 Loss:741.4097 Time:0m1.85s\n",
      "Valid Loss:518.8752\n",
      "Epoch:240 Batch:562/562 Loss:811.8420 Time:0m3.07s\n",
      "Valid Loss:519.6698\n",
      "Epoch:241 Batch:562/562 Loss:740.4429 Time:0m2.36s\n",
      "Valid Loss:514.6339\n",
      "Epoch:242 Batch:562/562 Loss:741.6603 Time:0m2.08s\n",
      "Valid Loss:511.5483\n",
      "Epoch:243 Batch:562/562 Loss:789.0538 Time:0m1.98s\n",
      "Valid Loss:517.3184\n",
      "Epoch:244 Batch:562/562 Loss:674.9229 Time:0m2.44s\n",
      "Valid Loss:511.9254\n",
      "Epoch:245 Batch:562/562 Loss:689.0046 Time:0m1.99s\n",
      "Valid Loss:518.0589\n",
      "Epoch:246 Batch:562/562 Loss:830.1138 Time:0m1.89s\n",
      "Valid Loss:522.1097\n",
      "Epoch:247 Batch:562/562 Loss:736.8986 Time:0m2.60s\n",
      "Valid Loss:513.8077\n",
      "Epoch:248 Batch:562/562 Loss:839.1262 Time:0m2.94s\n",
      "Valid Loss:525.9546\n",
      "Epoch:249 Batch:562/562 Loss:733.3685 Time:0m3.50s\n",
      "Valid Loss:517.3357\n",
      "Epoch:250 Batch:562/562 Loss:744.2078 Time:0m3.61s\n",
      "Valid Loss:522.7637\n",
      "Epoch:251 Batch:562/562 Loss:755.9023 Time:0m2.77s\n",
      "Valid Loss:517.4236\n",
      "Epoch:252 Batch:562/562 Loss:802.5014 Time:0m2.65s\n",
      "Valid Loss:514.3830\n",
      "Epoch:253 Batch:562/562 Loss:730.7865 Time:0m3.86s\n",
      "Valid Loss:522.7246\n",
      "Epoch:254 Batch:562/562 Loss:768.9457 Time:0m2.49s\n",
      "Valid Loss:525.7853\n",
      "Epoch:255 Batch:562/562 Loss:682.5627 Time:0m1.86s\n",
      "Valid Loss:522.9091\n",
      "Epoch:256 Batch:562/562 Loss:752.7533 Time:0m1.86s\n",
      "Valid Loss:520.6727\n",
      "Epoch:257 Batch:562/562 Loss:690.9368 Time:0m2.45s\n",
      "Valid Loss:525.4144\n",
      "Epoch:258 Batch:562/562 Loss:764.7570 Time:0m2.02s\n",
      "Valid Loss:521.8804\n",
      "Epoch:259 Batch:562/562 Loss:832.0359 Time:0m1.91s\n",
      "Valid Loss:524.8389\n",
      "Epoch:260 Batch:562/562 Loss:768.8866 Time:0m1.86s\n",
      "Valid Loss:521.1848\n",
      "Epoch:261 Batch:562/562 Loss:781.3213 Time:0m1.88s\n",
      "Valid Loss:515.0218\n",
      "Epoch:262 Batch:562/562 Loss:834.5677 Time:0m1.88s\n",
      "Valid Loss:518.6492\n",
      "Epoch:263 Batch:562/562 Loss:785.2384 Time:0m2.32s\n",
      "Valid Loss:517.5186\n",
      "Epoch:264 Batch:562/562 Loss:760.9826 Time:0m2.79s\n",
      "Valid Loss:516.3351\n",
      "Epoch:265 Batch:562/562 Loss:823.6926 Time:0m3.40s\n",
      "Valid Loss:518.4891\n",
      "Epoch:266 Batch:562/562 Loss:809.2625 Time:0m3.46s\n",
      "Valid Loss:512.9065\n",
      "Epoch:267 Batch:562/562 Loss:720.7032 Time:0m3.44s\n",
      "Valid Loss:519.7754\n",
      "Epoch:268 Batch:562/562 Loss:708.9392 Time:0m2.07s\n",
      "Valid Loss:519.9887\n",
      "Epoch:269 Batch:562/562 Loss:797.7337 Time:0m1.81s\n",
      "Valid Loss:523.7308\n",
      "Epoch:270 Batch:562/562 Loss:746.3230 Time:0m3.39s\n",
      "Valid Loss:519.3247\n",
      "Epoch:271 Batch:562/562 Loss:803.4074 Time:0m2.20s\n",
      "Valid Loss:525.2465\n",
      "Epoch:272 Batch:562/562 Loss:836.2451 Time:0m2.41s\n",
      "Valid Loss:526.0395\n",
      "Epoch:273 Batch:562/562 Loss:672.2296 Time:0m3.47s\n",
      "Valid Loss:519.7147\n",
      "Epoch:274 Batch:562/562 Loss:701.7419 Time:0m2.44s\n",
      "Valid Loss:512.6348\n",
      "Epoch:275 Batch:562/562 Loss:737.0413 Time:0m1.89s\n",
      "Valid Loss:517.3493\n",
      "Epoch:276 Batch:562/562 Loss:759.3913 Time:0m1.94s\n",
      "Valid Loss:516.9680\n",
      "Epoch:277 Batch:562/562 Loss:850.4086 Time:0m3.16s\n",
      "Valid Loss:523.4294\n",
      "Epoch:278 Batch:562/562 Loss:785.3621 Time:0m1.96s\n",
      "Valid Loss:521.8063\n",
      "Epoch:279 Batch:562/562 Loss:746.5322 Time:0m3.01s\n",
      "Valid Loss:518.8894\n",
      "Epoch:280 Batch:562/562 Loss:798.0870 Time:0m2.81s\n",
      "Valid Loss:523.1164\n",
      "Epoch:281 Batch:562/562 Loss:797.1068 Time:0m3.05s\n",
      "Valid Loss:520.7780\n",
      "Epoch:282 Batch:562/562 Loss:818.5566 Time:0m3.22s\n",
      "Valid Loss:518.9169\n",
      "Epoch:283 Batch:562/562 Loss:739.9310 Time:0m2.61s\n",
      "Valid Loss:512.8873\n",
      "Epoch:284 Batch:562/562 Loss:766.2607 Time:0m3.43s\n",
      "Valid Loss:521.8498\n",
      "Epoch:285 Batch:562/562 Loss:788.2178 Time:0m3.51s\n",
      "Valid Loss:524.9949\n",
      "Epoch:286 Batch:562/562 Loss:870.3126 Time:0m3.50s\n",
      "Valid Loss:518.0580\n",
      "Epoch:287 Batch:562/562 Loss:732.2174 Time:0m2.22s\n",
      "Valid Loss:510.6364\n",
      "Epoch:288 Batch:562/562 Loss:727.9622 Time:0m2.27s\n",
      "Valid Loss:517.9045\n",
      "Epoch:289 Batch:562/562 Loss:749.0892 Time:0m2.90s\n",
      "Valid Loss:514.7111\n",
      "Epoch:290 Batch:562/562 Loss:635.2654 Time:0m2.33s\n",
      "Valid Loss:521.8854\n",
      "Epoch:291 Batch:562/562 Loss:732.8919 Time:0m2.88s\n",
      "Valid Loss:512.4503\n",
      "Epoch:292 Batch:562/562 Loss:822.0230 Time:0m2.19s\n",
      "Valid Loss:513.6909\n",
      "Epoch:293 Batch:562/562 Loss:828.4493 Time:0m1.92s\n",
      "Valid Loss:519.0792\n",
      "Epoch:294 Batch:562/562 Loss:764.4420 Time:0m3.53s\n",
      "Valid Loss:517.8854\n",
      "Epoch:295 Batch:562/562 Loss:721.1706 Time:0m2.36s\n",
      "Valid Loss:521.6593\n",
      "Epoch:296 Batch:562/562 Loss:725.5866 Time:0m2.97s\n",
      "Valid Loss:523.4582\n",
      "Epoch:297 Batch:562/562 Loss:716.8461 Time:0m2.55s\n",
      "Valid Loss:523.1127\n",
      "Epoch:298 Batch:562/562 Loss:729.0392 Time:0m2.38s\n",
      "Valid Loss:523.5003\n",
      "Epoch:299 Batch:562/562 Loss:834.6115 Time:0m3.69s\n",
      "Valid Loss:520.8560\n",
      "Epoch:300 Batch:562/562 Loss:757.3575 Time:0m3.34s\n",
      "Valid Loss:518.9233\n",
      "Epoch:301 Batch:562/562 Loss:745.7574 Time:0m3.54s\n",
      "Valid Loss:522.8750\n",
      "Epoch:302 Batch:562/562 Loss:685.8988 Time:0m2.12s\n",
      "Valid Loss:517.7686\n",
      "Epoch:303 Batch:562/562 Loss:749.4160 Time:0m2.33s\n",
      "Valid Loss:514.8920\n",
      "Epoch:304 Batch:562/562 Loss:813.3024 Time:0m2.51s\n",
      "Valid Loss:517.9818\n",
      "Epoch:305 Batch:340/562 Loss:691.3989 Time:0m1.39s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4f90baef4da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnum_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#early stopping\n",
    "early_stopping = True\n",
    "tol = 0.0001\n",
    "patience = 10\n",
    "#training phase\n",
    "epochs = 1000\n",
    "start_time = time.time()\n",
    "#to plot loss curve after training\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "early_stop_epochs = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    epoch_start_time = time.time()\n",
    "    mlp.train()\n",
    "    num_batch = len(train_loader)\n",
    "    \n",
    "    for batch_id, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        y_pred = mlp(batch_x)\n",
    "\n",
    "        loss = criterion(y_pred, batch_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        elapsed_time = time.time() - epoch_start_time\n",
    "        elapsed_min = int(elapsed_time / 60)\n",
    "        elapsed_sec = elapsed_time - 60 * elapsed_min\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # cyclic learning rate\n",
    "        #scheduler.step()\n",
    "\n",
    "        print('\\rEpoch:{} Batch:{}/{} Loss:{:.4f} Time:{}m{:.2f}s'.format(epoch + 1, batch_id+1, \n",
    "                                                                          num_batch, loss.item(),\n",
    "                                                                          elapsed_min, elapsed_sec), end='')\n",
    "    print()\n",
    "    mlp.eval()\n",
    "    valid_loss = 0\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for batch_id, (batch_x, batch_y) in enumerate(test_loader):\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "    \n",
    "        y_pred = mlp(batch_x)\n",
    "        loss = criterion(y_pred, batch_y)\n",
    "        valid_loss += loss.item()\n",
    "    \n",
    "    valid_loss /= len(test_loader)\n",
    "    valid_losses.append(valid_loss)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    #save model when validation loss is minimum\n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        torch.save(mlp.state_dict(), 'mlp_pytorch_test.model')\n",
    "    \n",
    "    print('Valid Loss:{:.4f}'.format(valid_loss))\n",
    "    \n",
    "    # Learning rate scheduler for plateaus\n",
    "    #scheduler.step(valid_loss)\n",
    "    \n",
    "    #early stopping\n",
    "    if early_stopping and epoch > 0:\n",
    "        if np.abs(valid_losses[-1] - valid_losses[-2]) < tol:\n",
    "            early_stop_epochs += 1\n",
    "        else:\n",
    "            early_stop_epochs = 0\n",
    "        if early_stop_epochs == patience:\n",
    "            print(\"Validation loss has not changed more than {} for {} epochs. Stopping...\".format(tol, patience))\n",
    "            break\n",
    "    \n",
    "runtime = time.time() - start_time\n",
    "\n",
    "print(\"Total Runtime Elapsed: {:.0f} hours {:.0f} minutes {:.2f} seconds.\".format(runtime//3600, runtime%3600//60, runtime%3600%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Validation Loss is 509.9608\n",
      "Best iteration: 231\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot validation loss curve, this may help to notice overfitting\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(train_losses, label = \"Training Loss\")\n",
    "plt.plot(valid_losses, label = \"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc = 0)\n",
    "print('Minimum Validation Loss is {:.4f}'.format(min(valid_losses)))\n",
    "print(\"Best iteration: {}\".format(np.argmin(valid_losses) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([[6,0.031180191,51.51122955,-0.044059634,51.54066292,9681]])\n",
    "input_test = torch.tensor(x_test, dtype=torch.float, device=device )\n",
    "\n",
    "mlp.load_state_dict(torch.load('mlp_pytorch_test.model'))\n",
    "y_pred = mlp(input_test)\n",
    "y_pred = y_pred.data.cpu().numpy()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
